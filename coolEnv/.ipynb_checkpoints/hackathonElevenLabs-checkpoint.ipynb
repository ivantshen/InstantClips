{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddb632-7518-491a-ba8b-b5e12bbd4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "site.addsitedir('Lib/site-packages')\n",
    "import os\n",
    "from glob import glob\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models.task import Task\n",
    "import requests\n",
    "import ffmpeg\n",
    "import m3u8_To_MP4\n",
    "import json\n",
    "from elevenlabs.client import ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431924f3-bb33-450c-a0d9-3eddcc1c3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "KINDO_API_KEY = \n",
    "\n",
    "TL_API_KEY=\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "\n",
    "XI_API_KEY = \n",
    "elevenlabs = ElevenLabs(api_key=XI_API_KEY)\n",
    "\n",
    "\n",
    "indexId =  #twelvelabs index for footage\n",
    "writeIndexId =  #twelvelabs index for finished videos\n",
    "\n",
    "\n",
    "TOTAL_VIDEO_DURATION = 0\n",
    "INITIAL_PROMPT = \"pumpkin\"\n",
    "TITLE = \"pumpkin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4ea27-92d6-4f47-ac8a-1c4d31fc5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfx\n",
    "\n",
    "def generate_sound_effect(text: str, output_path: str, duration):\n",
    "   print(\"Generating sound effects...\")\n",
    "\n",
    "   result = elevenlabs.text_to_sound_effects.convert(\n",
    "       text=text,\n",
    "       duration_seconds=int(duration*.9),  # Optional, if not provided will automatically determine the correct length\n",
    "       prompt_influence=0.3,  # Optional, if not provided will use the default value of 0.3\n",
    "   )\n",
    "\n",
    "\n",
    "   with open(output_path, \"wb\") as f:\n",
    "       for chunk in result:\n",
    "           f.write(chunk)\n",
    "\n",
    "\n",
    "   print(f\"Audio saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e04c90-545a-4e65-81c7-a7dbed015148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestClip(page):\n",
    "    clipDurations = []\n",
    "    clipScores = []\n",
    "    clipVideoIds = []\n",
    "    clipUrls = []\n",
    "    for clip in page:\n",
    "        clipDurations.append(clip.end-clip.start)\n",
    "        clipScores.append(clip.score)\n",
    "        clipVideoIds.append(clip.video_id)\n",
    "        clipVideo = client.index.video.retrieve(indexId, clip.video_id)\n",
    "        clipUrls.append(clipVideo.hls.video_url)\n",
    "    return findBestClip(clipDurations, clipScores, clipVideoIds,clipUrls)\n",
    "\n",
    "def findBestClip(durations,scores,videoIds,urls):\n",
    "    i = 0\n",
    "    bestConfidence = 0;\n",
    "    bestClipFound = videoIds[0];\n",
    "    bestUrl = \"\"\n",
    "    bestDuration = 0;\n",
    "    for d in durations:\n",
    "        if(int(d)>4 and int(d)<=22):\n",
    "            if(int(scores[i])>bestConfidence and not checkIfUsedClip(videoIds[i])):\n",
    "                bestDuration = d;\n",
    "                bestConfidence = scores[i]\n",
    "                bestClipFound = videoIds[i]\n",
    "                bestUrl = urls[i]\n",
    "        i = i+1\n",
    "    print(str(bestClipFound) +\" \"+ str(bestConfidence) + bestUrl)\n",
    "    m3u8_To_MP4.multithread_download(bestUrl)\n",
    "    return bestClipFound, bestDuration;\n",
    "def checkIfUsedClip(id):\n",
    "    global usedVideoIds\n",
    "    for i in usedVideoIds:\n",
    "        if(id==i):\n",
    "            print(\"tried to add repeated video\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generateClip(textQuery: str, currentClipIndex: int):\n",
    "    #Search Query\n",
    "    global TOTAL_VIDEO_DURATION\n",
    "    global TITLE\n",
    "    global usedVideoIds\n",
    "    search_results = client.search.query(index_id=indexId,\n",
    "                                     query=textQuery,\n",
    "                                     options=[\"visual\"])\n",
    "    coolId, coolDuration = getBestClip(search_results.data)\n",
    "    usedVideoIds.append(coolId)\n",
    "    TOTAL_VIDEO_DURATION = TOTAL_VIDEO_DURATION + int(coolDuration)\n",
    "\n",
    "    #generatedNarration = stockClient.generate.text(video_id = coolId,\n",
    "    #                          prompt = \"Write a \" + str(int(coolDuration*1.4)) + \" word long frightening narration describing the subject of my video. Be a storyteller, be engaging.\"\n",
    "    #)\n",
    "\n",
    "    title = client.generate.text(video_id = coolId,\n",
    "                          prompt = \"Write ONE unique word for my video with NO SPECIAL CHARACTERS. NO QUOTATIONS\"\n",
    "    )\n",
    "\n",
    "    generatedSoundPromptSubject = client.generate.text(video_id = coolId,\n",
    "                          prompt = \"Write an eerie ten word sound effect about only the MAIN SUBJECT of the video with NO SPECIAL CHARACTERS. NO COMMAS. NO VOICES. NO WHISPERS\"\n",
    "    )\n",
    "\n",
    "    generatedSoundPromptBackground = client.generate.text(video_id = coolId,\n",
    "                          prompt = \"Write a scary ten word about only the BACKGROUND sound effect for the video. NO SPECIAL CHARACTERS. NO COMMAS\"\n",
    "    )\n",
    "\n",
    "    nextQuery = client.generate.text(video_id = coolId,\n",
    "                          prompt = \"Write a two to three word prompt describing a loosely related topic to the video content. Go crazy. NO SPECIAL CHARACTERS. NO QUOTATIONS\"\n",
    "    )\n",
    "    \n",
    "    #generatedMovieSoundEffects = stockClient.generate.text(video_id = coolId,\n",
    "    #                          prompt = \"Write a six word long description of loud blaring instrumental movie trailer sound effects with NO SPECIAL CHARACTERS\"\n",
    "    #)\n",
    "    \n",
    "    os.rename(\"m3u8_To_MP4.mp4\",f\"{title.data}\" +str(currentClipIndex)+\".mp4\")\n",
    "    #print(\"Narration: \"+f\"{generatedNarration.data}\")\n",
    "    print(\"Subject: \" + f\"{generatedSoundPromptSubject.data}\")\n",
    "    print(\"Background: \" + f\"{generatedSoundPromptBackground.data}\")\n",
    "    print(\"Next query: \" + f\"{nextQuery.data}\")\n",
    "    #print(\"movieSFX: \"+f\"{generatedMovieSoundEffects.data}\")\n",
    "    generate_sound_effect(f\"{generatedSoundPromptSubject.data}\", f\"{title.data}\"+str(currentClipIndex)+\"SubjectSFX.mp4\",coolDuration)\n",
    "    generate_sound_effect(f\"{generatedSoundPromptBackground.data}\", f\"{title.data}\"+str(currentClipIndex)+\"BackgroundSFX.mp4\",coolDuration)\n",
    "    #generate_sound_effect(f\"{generatedMovieSoundEffects.data}\", f\"{title.data}\"+\"MovieSFX.mp4\",coolDuration)\n",
    "    \n",
    "    return f\"{nextQuery.data}\", f\"{title.data}\"+str(currentClipIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810f6e4-5e95-4229-b8b4-ce679edf2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedVideoIds = []\n",
    "secondPrompt, firstTitle = generateClip(INITIAL_PROMPT,0)\n",
    "thirdPrompt, secondTitle = generateClip(secondPrompt,1)\n",
    "fourthPrompt, thirdTitle = generateClip(thirdPrompt,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e790ab-7f2b-43f6-b486-3880dbb3129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1SubjectSFX = ffmpeg.input(firstTitle+\"SubjectSFX.mp4\")\n",
    "input1BackgroundSFX = ffmpeg.input(firstTitle+\"BackgroundSFX.mp4\")\n",
    "\n",
    "\n",
    "concatAudio1 = ffmpeg.filter([input1SubjectSFX, input1BackgroundSFX], 'amix', inputs=2,duration='longest')\n",
    "\n",
    "\n",
    "input2SubjectSFX = ffmpeg.input(secondTitle+\"SubjectSFX.mp4\")\n",
    "input2BackgroundSFX = ffmpeg.input(secondTitle+\"BackgroundSFX.mp4\")\n",
    "\n",
    "concatAudio2 = ffmpeg.filter([input2SubjectSFX, input2BackgroundSFX], 'amix', inputs=2,duration='longest')\n",
    "\n",
    "input3SubjectSFX = ffmpeg.input(thirdTitle+\"SubjectSFX.mp4\")\n",
    "input3BackgroundSFX = ffmpeg.input(thirdTitle+\"BackgroundSFX.mp4\")\n",
    "\n",
    "concatAudio3 = ffmpeg.filter([input3SubjectSFX, input3BackgroundSFX], 'amix', inputs=2,duration='longest')\n",
    "\n",
    "audioMixed = ffmpeg.filter([concatAudio1,concatAudio2,concatAudio3], 'concat', n=3, a=1, v=0)\n",
    "#Combine merged audio with the video\n",
    "(\n",
    "    ffmpeg\n",
    "    .output(audioMixed,\"processed_folder/wip\"+TITLE+\"AUDIOCONCAT.mp4\", vcodec='copy', acodec='aac',strict='experimental')\n",
    "    .run()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "video1 = ffmpeg.input(firstTitle+\".mp4\")\n",
    "video2 = ffmpeg.input(secondTitle+\".mp4\")\n",
    "video3 = ffmpeg.input(thirdTitle+\".mp4\")\n",
    "\n",
    "\n",
    "videoMixed = ffmpeg.concat(video1, video2, video3, v=1, a=0).node\n",
    "\n",
    "(\n",
    "    ffmpeg\n",
    "    .output(videoMixed[0], \"processed_folder/wip\"+TITLE+\"VideoPart.mp4\")\n",
    "    .run()\n",
    ")\n",
    "\n",
    "funkyAudio = ffmpeg.input(\"processed_folder/wip\"+TITLE+\"AUDIOCONCAT.mp4\")\n",
    "funkyVideo = ffmpeg.input(\"processed_folder/wip\"+TITLE+\"VideoPart.mp4\")\n",
    "\n",
    "# Combine merged audio with the video\n",
    "try:\n",
    "    (\n",
    "        ffmpeg\n",
    "        .output(funkyVideo, funkyAudio, \"needsNarrationClips/\"+TITLE+\"NeedsNarrating.mp4\", vcodec='copy', acodec='aac',format='mp4',strict='experimental')\n",
    "        .run(capture_stdout=True, capture_stderr=True)\n",
    "    )\n",
    "except ffmpeg.Error as e:\n",
    "    print(\"FFmpeg Error:\", e.stderr.decode('utf-8'))\n",
    "os.remove(firstTitle+\".mp4\")\n",
    "os.remove(secondTitle+\".mp4\")\n",
    "os.remove(thirdTitle+\".mp4\")\n",
    "os.remove(firstTitle+\"SubjectSFX.mp4\")\n",
    "os.remove(secondTitle+\"SubjectSFX.mp4\")\n",
    "os.remove(thirdTitle+\"SubjectSFX.mp4\")\n",
    "os.remove(firstTitle+\"BackgroundSFX.mp4\")\n",
    "os.remove(secondTitle+\"BackgroundSFX.mp4\")\n",
    "os.remove(thirdTitle+\"BackgroundSFX.mp4\")\n",
    "os.remove(\"processed_folder/wip\"+TITLE+\"AUDIOCONCAT.mp4\")\n",
    "os.remove(\"processed_folder/wip\"+TITLE+\"VideoPart.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ca9de-2b13-4c0a-bf3b-e1b6564a1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "needNarratingId = \"\"\n",
    "\n",
    "task = client.task.create(index_id=writeIndexId, file=\"needsNarrationClips/\"+TITLE+\"NeedsNarrating.mp4\", language=\"en\")\n",
    "needNarratingId = task.video_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048988a-ba71-47ad-9591-e75c4e5fc916",
   "metadata": {},
   "source": [
    "# WAIT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b45d71-2638-4645-a1ee-16fcf782ef5d",
   "metadata": {},
   "source": [
    "# WAIT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c692216-8121-4609-af02-00a130572fce",
   "metadata": {},
   "source": [
    "# WAIT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bd07f-9b73-4487-a27e-b40ab864f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedNarration = client.generate.text(video_id = needNarratingId,\n",
    "                              prompt = \"Write a bloodcurdling \"+str((TOTAL_VIDEO_DURATION-TOTAL_VIDEO_DURATION%5)*2)+\" word introduction to a horror film using the video as a basis. Begin by asking multiple questions. Refer to the audience as you. Find FIVE ordered unordinary specific details throughout the video and refer to them in the plot mysteriously. Use active voice. Be engaging, go wild! Ask questions to the audience. Announce a release date at the end.\" \n",
    "    )\n",
    "print(\"narration: \"+f\"{generatedNarration.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24314af0-4b68-4428-9908-c33b487cd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kindo translation\n",
    "MODEL_NAME = 'groq/llama-3.1-70b-versatile'\n",
    "language = \"JAPANESE\"\n",
    "text = f\"{generatedNarration.data}\"\n",
    "\n",
    "\n",
    "# Define the endpoint and headers\n",
    "url = \"https://llm.kindo.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"api-key\": KINDO_API_KEY,\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": f\"Translate the following in {language} without the initial introductions (straight into the translation): {text}\"}]\n",
    "}\n",
    "\n",
    "\n",
    "# Make the POST request\n",
    "kindoResponse = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "generatedKindoNarration = kindoResponse.json()['choices'][0]['message']['content']\n",
    "\n",
    "# Print the response\n",
    "print(generatedKindoNarration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b816fb-8fa3-491b-8363-fa654179b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#narration\n",
    "CHUNK_SIZE = 1024\n",
    "VOICE_ID = \"7fbQ7yJuEo56rYjrYaEh\"  # ID of the voice model to use\n",
    "TEXT_TO_SPEAK = f\"{generatedNarration.data}\"#generatedKindoNarration\n",
    "OUTPUT_PATH = \"needsNarrationClips/\"+TITLE+\"Narration.mp4\"  # Path to save the output audio file\n",
    "tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
    "\n",
    "headers = {\n",
    "   \"Accept\": \"application/json\",\n",
    "   \"xi-api-key\": XI_API_KEY\n",
    "}\n",
    "data = {\n",
    "   \"text\": TEXT_TO_SPEAK,\n",
    "   \"model_id\": \"eleven_multilingual_v2\",\n",
    "   \"voice_settings\": {\n",
    "       \"stability\": 0.5,\n",
    "       \"similarity_boost\": 0.8,\n",
    "       \"style\": 0.0,\n",
    "       \"use_speaker_boost\": True\n",
    "   }\n",
    "}\n",
    "\n",
    "response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
    "if response.ok:\n",
    "   # Open the output file in write-binary mode\n",
    "   with open(OUTPUT_PATH, \"wb\") as f:\n",
    "       # Read the response in chunks and write to the file\n",
    "       for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "           f.write(chunk)\n",
    "   # Inform the user of success\n",
    "   print(\"Audio stream saved successfully.\")\n",
    "else:\n",
    "   # Print the error message if the request was not successful\n",
    "   print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc8de9-cf6c-4153-a56c-6d202b9f46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputBaseVideo = ffmpeg.input(\"needsNarrationClips/\"+TITLE+\"NeedsNarrating.mp4\")\n",
    "inputNarration = ffmpeg.input(OUTPUT_PATH)\n",
    "\n",
    "audioMixed = ffmpeg.filter([inputBaseVideo.audio,inputNarration.audio], 'amix', inputs=2,duration='longest')\n",
    "# Combine merged audio with the video\n",
    "try:\n",
    "    (\n",
    "        ffmpeg\n",
    "        .output(inputBaseVideo.video, audioMixed, \"FinalProduct/\"+TITLE+\"Video.mp4\", vcodec='copy', acodec='aac',format='mp4',strict='experimental')\n",
    "        .run(capture_stdout=True, capture_stderr=True)\n",
    "    )\n",
    "except ffmpeg.Error as e:\n",
    "    print(\"FFmpeg Error:\", e.stderr.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b0d00-b490-469e-9254-3525c1acddca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
